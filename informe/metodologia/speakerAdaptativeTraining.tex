El Speaker-Adaptive Training es una técnica que permite tomar un modelo ya entrenado y adaptarlo para asimilar características de un nuevo hablante. Esta técnica nace de la idea de que construir un corpus de datos es costoso en espacio de almacenamiento, tiempo de grabación y etiquetado, por lo que resulta más económico generar una modelo base a partir de un gran corpus de datos y luego adaptarlo con características particulares del hablante especifico que queramos.

Nuestro objetivo para este trabajo es utilizar esta herramienta para aproximar las características de uno de los hablantes al otro para que sus identidades sean indistinguibles. Como prueba de concepto se entrenó el modelo principal con \textit{CMU-ARCTIC-SLT} y se le realizó Speaker-Adaptive Training junto con \textit{loc1\_pal} utilizando los scripts provistos en la sección de descargas de HTS \cite{speakerAdaptativeTrainingLink}.

Dentro del adaptive training existen varias técnicas, en este trabajo utilizaremos \textit{offline supervised adaptation}, que tiene como requisito adicional conocer las transcripciones fonéticas del segundo corpus. 

Las pruebas no resultaron concluyentes. Las oraciones sintetizadas no solamente adquirían la identidad del segundo hablante sino también sus características fonéticas. Dicho de otra manera, si lo que buscábamos era obtener un hablante inglés que pudiera ser reconocido como el mismo locutor que \textit{loc1\_pal} pero con sus características fonéticas intactas (una pronunciación suavizada del fono /\textipa{r}/ (\textit{perro}), por ejemplo), lo que en realidad obtuvimos fue una voz idéntica a \textit{loc1\_pal}. Si bien existen indicios que indican que es posible generar un modelo con las características deseadas \cite{statisticalParam} \cite{speakerSim}, dada la complejidad del método y los largos periodos de entrenamiento ($36$ horas aproximadamente) decidimos abandonar este camino y continuar con la fase de evaluación perceptual sobre las voces generadas con las técnicas de interpolación.