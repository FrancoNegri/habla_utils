\section{Preparación de los datos}

\subsection{Primer Corpus En Castellano}

Al comienzo de la investigación comenzamos con un solo corpus de datos, \textit{secyt-mujer}\cite{secytMujer}. El mismo está compuesto por $741$ oraciones cortas declarativas habladas por una locutora profesional de origen Español Rioplatense, equivalentes a $48$ minutos de habla.

A continuacion tres ejemplos de las oraciones articuladas por la locutora:

\indent\indent \textit{La voluntad del juez fue impuesta en tribunales.}

\indent\indent \textit{Los vinos uruguayos han mejorado en el último lustro.}

\indent\indent \textit{Al atardecer se puso su disfraz juglaresco.}

Como parte inicial del trabajo es indispensable construir el etiquetado fonético para el corpus. Estos etiquetados consistirán principalmente de una lista de fonos dónde se indica donde comienza y donde termina cada uno en el audio. La calidad de las oraciones que logremos sintetizar a posteriori dependerá fuertemente del etiquetado, por lo que es necesario prestar especial cuidado en que las transcripciones estén lo mejor alineadamente posible con los audios. Las transcripciones serán necesarias para entrenar los modelos de HMM+GMM, extrayendo de aquí tanto la información acústica para cada fono (cosas tales como la frecuencia principal, la duración, etc) como así también información contextual (por ejemplo: como suena un fonema cuando está seguido de algún otro, al principio de una oración, si se encuentra en un diptongo). Por esto una mala transcripción se traducirá indefectiblemente en un mal modelo y malas oraciones sintetizadas.

Realizamos varias pruebas de concepto utilizando HTS y este corpus, experimentando con diversos métodos para obtener el etiquetado fonético. 

La primera estrategia consistió en utilizar alineamiento automático con EHMM alignment \cite{phoneticCapturing} empleando Festival y Festvox. Estos programas tienen como ventaja que tanto la anotación del corpus como la generación de oraciones utilizadas para la síntesis presentan el mismo repertorio fonético. Esto es útil ya que podemos garantizar que el entrenamiento y la síntesis están utilizando el mismo método de generación de trazas/oraciones.

Los resultados preliminares con este método fueron bastante negativos: los audios generados resultaban poco inteligibles notándose claros defectos acústicos, El más notable siendo el fono /\textipa{r}/ que se asemejaba más a /\textipa{R}/.

Utilizando Praat para visualizar el alineamiento entre las transcripciones foneticas y los audios, descubrimos que la alineación estaba desfasada algunas milésimas de segundo. Dado que para el alineamiento automatico es necesario alinear los audios del corpus con audios sintetizados con festival, sospechamos que pudo haber problemas con la calidad del corpus o que los audio sintetizado estaba demasiado alejado del audio objetivo.

Dado que para el corpus contamos con las transcripciones fonéticas anotadas de manera manual, procedimos a implementar un híbrido con EHMM. En este híbrido tomamos las anotaciones hechas a mano para cada fonema y la información contextual y el repertorio fonético generado a partir del proceso de EHMM. De esta manera buscamos mejorar la alineación pero manteniendo el mismo repertorio fonético y la misma meta-información brindada por el alineamiento automático.

El modelo generado con estas transcripciones mixtas resultó superior a los generadas solo con alineamiento automático. Aún así los audios sintetizados todavía no alcanzaron una calidad aceptable, realizando pruebas todavía notamos que el sonido resultaba metálico y las frases poco inteligibles. Además se pudo percibir de manera informal otros detalles tales como que la voz original tenía un pitch mayor que la producida por los modelos, alrededor de un $10\%$.

Para intentar mejorar la calidad de los audios en este punto sumamos otro corpus de datos.

\subsection{Segundo Corpus En Castellano}

En este punto de la investigación obtenemos un segundo corpus de datos \textit{loc1\_pal} \cite{loc1pal} con $1593$ oraciones cortas con una mezcla entre fraces declarativas y interrogativas del $80\%$ y $20\%$ aproximadamente, pronunciadas por una locutora profecional con ascento Rioplatense con aproximadamente $2$ horas y $26$ minutos de habla. Con este nuevo conjunto de datos esperamos conseguir mejores resultados.

Presentamos tres ejemplos de las oraciones articuladas por la locutora:

\indent\indent \textit{Alvarez se había animado a contarle un chiste}

\indent\indent \textit{Alzó la voz para ahuyentar a los perros.}

\indent\indent \textit{Ayer el general cumplió ochenta años.}

\aclararMismasConjuntosConOverlaping

Para este corpus no contábamos con transcripciones fonéticas manuales por lo que nos vimos forzados a utilizar EHMM nuevamente. Aún así, los resultados fueron superiores a los conseguidos con \textit{secyt-mujer}. 

Al contrario que en \textit{secyt-mujer}, al visualizar este corpus con Praat, no apreciamos mayores desfasajes con las anotaciones foneticas.

Ademas los audios sintetizados resultaban inteligibles y con un marcado acento rioplatense. Tras algunas pruebas de concepto donde se experimentó con varios parámetros modificables dentro de HTK, logramos obtener resultados que superaban de manera significativa aquellos obtenidos previamente con \textit{secyt-mujer}. Por consiguiente consideramos que los audios generados habían alcanzado una buena calidad que resultara ininteligible y aceptable para el objetivo de la investigación, por lo que decidimos utilizar uno de estos modelos para el resto del trabajo.

%pag 28 htbook:
%The single biggest problem in building context-dependent HMM systems is always data insuffi-
%ciency. The more complex the model set, the more data is needed to make robust estimates of its

Especulamos que la disparidad en la calidad de los resultados es causada principalmente por la cantidad de audios y horas de habla de cada corpus\cite{whyItSucked}. Consideramos que esto juega un papel predominante en la calidad de los TTS generados, aún cuando se utiliza un método de etiquetado puramente automático y propenso a errores sistemáticos en el alineamiento.

%Finalmente necesitamos generar otra voz con un idioma diferente que nos permita interpolar con el modelo previamente detallado. Para esto utilizamos el corpus

\subsection{Corpus En inglés}

Por otro lado entrenamos una voz en inglés \textit{CMU-ARCTIC-SLT}\cite{cmuArtic} con $1132$ oraciones en inglés y $56$ minutos de habla articuladas por una mujer Estadounidense, disponible en la página de hts \cite{hts}. Ya que este corpus venía a modo de demo con hts, asumimos que los parámetros de entrenamiento y las transcripciones fonéticas ya habían sido seleccionadas de manera apropiada, por lo que no intentamos mejorar la calidad de las transcripciones fonéticas mas allá de lo que la demo ofrecía.

Presentamos tres ejemplos de las oraciones articuladas por la locutora:

\indent\indent \textit{Author of the danger trail, Philip Steels, etc.}

\indent\indent \textit{Not at this particular case, Tom, apologized Whittemore.}

\indent\indent \textit{For the twentieth time that evening the two men shook hands.}

Para este trabajo todos los audios usarán sampling rate de $48$kHz, precisión de $16$bits, mono.

El rango de extracción de frecuencia principal para  utilizado fue de $100$hz a $350$hz.

Una lista extensiva de los parámetros utilizados para el entrenamiento se puede ver en el apéndice $3$.

% hablar de intelibililidad como para ya ir adelantando el tema
% Cosas para hablar:
% 5 fonemas.
%TODO: phonetically balanced?
% desarrollar generacion de uternaces: secty alineaminento mixto: tiempos a mano, features automaticos.
